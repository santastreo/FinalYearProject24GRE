{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBC1XIN5ns7G"
      },
      "source": [
        "# SOURCE CODE USED AND ADDED OWN IMPLEMENTATION ON\n",
        "\n",
        "https://www.youtube.com/watch?v=9he4XKqqzvE&t=911s\n",
        "\n",
        "https://github.com/PradipNichite/Youtube-Tutorials/blob/main/FineTune_BERT_Model_Youtube.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjBrn_Wbb_dg"
      },
      "source": [
        "# FORCE INSTALL THESE 3 LIBRARIES FOR IT TO RUN PROPERLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmeRO-7Osp1W",
        "outputId": "62325239-f1c1-4abd-c5cb-cb9e386ee37a"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQQzuYF4cGjj"
      },
      "source": [
        "# IMPORT TORCH AND CLEAR THE CUDA CACHE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXyZHwGeIvbf"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "import torch # because we are working with PyTorch model\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgX1OGrYb5r0"
      },
      "source": [
        "# IMPORT NECESSARY LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESqjvQbmnY5y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np # calculations such as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re # regular expressions\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import BertForSequenceClassification, TrainingArguments\n",
        "from transformers import Trainer as HfTrainer\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZpPzgTDucTD"
      },
      "source": [
        "# WE LOAD OUR DATASET TO A OBJECT CALLED \"data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nr0nt-04oQTs"
      },
      "outputs": [],
      "source": [
        "#dataset is being loaded from my personal google drive\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/dataset/dataset2.csv\",error_bad_lines=False, engine=\"python\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgdG4iI3vDzk"
      },
      "source": [
        "# RENAMING THE DEFAULT COLUMN NAME, \"headline\" TO CUSTOM ONE, \"label\". ALSO RENAMING THE DATA IN LABEL FROM \"-1\" TO \"1\" TO ENSURE SIMPLE BINARY CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WVSd_1E3rW9"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "data = data.rename(columns={'headline': 'text'})\n",
        "data['label'] = data['label'].replace(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "airJKqEe3rZk",
        "outputId": "e17935b6-ce6b-4d51-d06d-3081a6ebe383"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-861e5b8f-e07b-4a9a-a30e-c6fdb34b2cb6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cock  suck before you piss around on my work</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>you are  gay or antisemmitian archangel white ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fuck your filthy mother in the ass  dry</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get fuck  ed up  get fuck  ed up got a drink t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stupid peace of  shit  stop deleting my stuff ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-861e5b8f-e07b-4a9a-a30e-c6fdb34b2cb6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-861e5b8f-e07b-4a9a-a30e-c6fdb34b2cb6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-861e5b8f-e07b-4a9a-a30e-c6fdb34b2cb6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e02b5ea-52a0-4483-b6cd-24b9c159f5f4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e02b5ea-52a0-4483-b6cd-24b9c159f5f4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e02b5ea-52a0-4483-b6cd-24b9c159f5f4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0       cock  suck before you piss around on my work      1\n",
              "1  you are  gay or antisemmitian archangel white ...      1\n",
              "2            fuck your filthy mother in the ass  dry      1\n",
              "3  get fuck  ed up  get fuck  ed up got a drink t...      1\n",
              "4  stupid peace of  shit  stop deleting my stuff ...      1"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMUUVz0RxwZN"
      },
      "source": [
        "# DATA ANALYSIS AND VISUALISATION:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPY7vNv83rcR"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "## counting number of texts, and which are toxic(1) and non-toxic(0)\n",
        "print(f\"No of texts: {data['text'].count()}\")\n",
        "print(f\"No of toxic: {(data['label'] == 1).sum()} ({int((data['label'] == 1).sum()*100 / data['label'].count())}%)\")\n",
        "print(f\"No of non-toxic: {(data['label'] == 0).sum()} ({int((data['label'] == 0).sum()*100 / data['label'].count())}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVlp-ZiJ3rek"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "##produces a bar chart and piechart\n",
        "# Visualisation\n",
        "sns.set_style('whitegrid')\n",
        "# Barplot describes the count of the class labels\n",
        "plt.figure(figsize = (12, 6))\n",
        "sns.countplot(data = data, x = 'label');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qChaprq6w9X"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "data.isnull().sum() # check for null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyAB7JjVUUJf"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "data.dropna(inplace=True) #we drop the row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPiyA5w-VAYI"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "data.isnull().sum() # check for null values again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCUBjb2m6xCR"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "data.duplicated().sum() # check for duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-RyWiDS6xE_"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "data = data.drop_duplicates(keep='first') # remove duplicates\n",
        "print(data.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg0-W5Va-cU6"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "##counts number again for updated values after dropping null values and duplicates\n",
        "print(f\"No of texts: {data['text'].count()}\")\n",
        "print(f\"No of toxic: {(data['label'] == 1).sum()} ({int((data['label'] == 1).sum()*100 / data['label'].count())}%)\")\n",
        "print(f\"No of non-toxic: {(data['label'] == 0).sum()} ({int((data['label'] == 0).sum()*100 / data['label'].count())}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "ZyqWSHIq6xJk",
        "outputId": "e1758673-75d5-4270-fb80-d5d395a524cb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#my addition to source code\n",
        "# displays pie chart visualisation of data distribution\n",
        "plt.pie(data['label'].value_counts(), labels = ['1','0'], colors = sns.color_palette('pastel')[3:5], autopct='%.0f%%' )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNkSeGtSFwhg"
      },
      "source": [
        "# DATA PREPROPRESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#helps in reducing complexity of textual data, removing noise and ensuring consistency which ultimately enhances\n",
        "#performance by providing cleaner and more structured input data to learn from"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITwxd9wo6xQU"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "def cleaning(txt):\n",
        "    # Ensure the input is a string\n",
        "    if not isinstance(txt, str):\n",
        "        return \"\"\n",
        "\n",
        "    # case folding\n",
        "    text = txt.lower()\n",
        "\n",
        "    # remove multiple space, tabs, and newlines\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "\n",
        "    # remove links\n",
        "    text = text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
        "\n",
        "    # remove special characters\n",
        "    text = text.encode('ascii', 'replace').decode('ascii')\n",
        "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
        "\n",
        "    # remove punctuation\n",
        "    punct = set('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')  # Define punctuation set\n",
        "    text = ''.join([word for word in text if word not in punct])\n",
        "\n",
        "    # remove single character\n",
        "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
        "\n",
        "    # remove numbers\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "\n",
        "    # remove multiple spaces (again)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGmVtCOJ6xSf"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "#apply cleaning function to every text\n",
        "data['text_cleaned'] = data['text'].apply(lambda x: cleaning(x))\n",
        "data = data[['text', 'text_cleaned', 'label']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZGBulT26xUl"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "#eliminating unimportant words, allowing model to focus on important words instead\n",
        "\n",
        "#stopword removal\n",
        "stop = stopwords.words('english')\n",
        "data['text_cleaned'] = data['text_cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7_vR9yX8CFw"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "#strips words back to the root word, using wordnet library.\n",
        "\n",
        "#Lemmmanization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# maps parts of speech (POS) tags from \"pos_tag\" function to the POS tags recognised by the wordnet lemmatizer\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "# takes a string as input, tokenizes it into words and then lemmatizes each word using lemmatizer with appropriate POS tags obtained from\n",
        "#\"get_word_net\", then the lemmatized words are joined back to a string\n",
        "def do_lemma(string):\n",
        "    lemmatized = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in nltk.word_tokenize(string)])\n",
        "    return lemmatized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE0JYfXp8CH6"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "#test\n",
        "sentence = \"The striped bats are hanging on their feet for best\"\n",
        "lemmatized = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in nltk.word_tokenize(sentence)])\n",
        "print(do_lemma(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "095PDFGR8CKd"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "data['text_cleaned'] = data['text_cleaned'].apply(lambda x: do_lemma(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LbwDBZ98CMx"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2AYLYCx8CO5"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "# we drop the old text column and replace the new cleaned text column as the new main text column\n",
        "data = data.drop(['text'], axis=1)\n",
        "data = data.rename(columns = {'text_cleaned' : 'text'})\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLNqxaQ29Vgu"
      },
      "outputs": [],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXKqjQ1Ei8Rr"
      },
      "source": [
        "# LOADING BERT AND TOKENIZING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_86hKpIToQbb"
      },
      "outputs": [],
      "source": [
        "# loading the bert model and its tokenizer\n",
        "# using uncased for smaller model size and uses words in lowercase\n",
        "# BERT looks at left and right context of each word\n",
        "# also uses advanced techniques like WordPiece, splits words into subwords i.e 3\n",
        "# generates embeddings (numerical representations) that capture the context of words in a sentence.\n",
        "# The same word can have different embeddings based on its surrounding words, allowing for a richer understanding of language nuances.\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDHem1yKoQgO"
      },
      "outputs": [],
      "source": [
        "#set model to gpu\n",
        "\n",
        "model = model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvLM6gIZoQio"
      },
      "outputs": [],
      "source": [
        "#Testing with sample text, output should be in a form of a dictionary, with 3 keys, each outputted as a list of lists\n",
        "\n",
        "sample_data = [\"I am eating\",\"I am playing \"]\n",
        "tokenizer(sample_data, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "#3 keys :\n",
        "#input id - token id for each sentence\n",
        "#token type id - used if there are multiple sentences per input\n",
        "#attention mask - mask that indicates which tokens the model should pay attention to and which are padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7_3pTHMoQk9"
      },
      "outputs": [],
      "source": [
        "# Tokenizing\n",
        "\n",
        "# set as \"list\" as the tokenizer expects a list of strings.\n",
        "\n",
        "X = list(data[\"text\"])\n",
        "y = list(data[\"label\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "#split 80% training and 20% validation(testing)(acts as unseen data to evaluate the models performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4R9H9GOoQnZ"
      },
      "outputs": [],
      "source": [
        "X_train_tokenized.keys()\n",
        "\n",
        "#outout should just be : dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifa4vLeZoQpw"
      },
      "outputs": [],
      "source": [
        "print(X_train_tokenized['attention_mask'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY3IiHo_oQsX"
      },
      "outputs": [],
      "source": [
        "len(X_train),len(X_val)\n",
        "\n",
        "# 14,558 training and 3640 val = 18,198 total dataset records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDJfihgdjFOV"
      },
      "source": [
        "# CREATING CUSTOM PYTORCH DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#THIS WAS PART OF THE SOURCE CODE\n",
        "\n",
        "#To my understanding:\n",
        "\n",
        "#acts as a contrainer for the preprocessed data, ensuring that the tokenized texts and their corresponding labels are stored\n",
        "#in a structued format, feeding the data into the model in a consistent and manageable way.\n",
        "\n",
        "#dataset class is also designed to work directly with the tokenized data, this intergration means the dataset knows how to handle and\n",
        "#store these tokenized inputs, including attention masks, which are essention for BERT to understand the meaningful parts of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tspxO8qoQub"
      },
      "outputs": [],
      "source": [
        "# Create torch dataset\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    # constructor, intialising Dataset object with encodings and labels\n",
        "    # encodings = dictionary containing tokenized X_train data from the bert tokenizer\n",
        "    # labels = correspending labels indicating whether a text is toxic or not\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    #fetches individual items (encoded text and its label) by index\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "    # returns the length of the input ids\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-GQqTk2oQxF"
      },
      "outputs": [],
      "source": [
        "#two instances of the Dataset class creacted for training and validation purposes\n",
        "#these datasets use the tokenized text and their associated labels\n",
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS88YjJSoQzh"
      },
      "outputs": [],
      "source": [
        "train_dataset[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE4ZkYDDoQ1t"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p):\n",
        "    print(type(p))\n",
        "    pred, labels = p #takes a tuple containing predictions and actual labels\n",
        "    pred = np.argmax(pred, axis=1) #uses np.argmax to determine the most likely class label from the predictions\n",
        "    #then calculates key metrics below:\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFSHUrHJjLIk"
      },
      "source": [
        "# SETTING CLASS WEIGHTS TO HANDLE DATA IMBALANCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#random sampling - repeats existing samples\n",
        "#oversampling - replicates samples from minority class or methods like smote (creates synethic data)\n",
        "#undersampling - removes samples from majority class\n",
        "\n",
        "#all the above involve directly altering the dataset, potentially affecting the integrity of the dataset\n",
        "\n",
        "#i decided to use class weights, which affect the model, not the dataset, thus leaving the dataset as is\n",
        "#class weights make sure the model pays attention to all examples, but it distributes more weight to the minority class, and less to the\n",
        "#majority class\n",
        "#class weights are then passed to a loss function, which helps the model realise if it made a mistake, and penalizes it more for making these\n",
        "#mistakes because the minority class is lesser than the majority."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWN8SWSZEIJh"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "# Compute class weights for handling imbalanced dataset\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced', # automatically adjust weights inversely proportional to class frequencies in the input data\n",
        "    classes=np.unique(y_train), #calculates the unique classes in training label\n",
        "    y=y_train # training label data, this is used to determine the frequency of each class.\n",
        ")\n",
        "# Convert class weights to a tensor\n",
        "weights = torch.tensor(class_weights, dtype=torch.float) #the class weights are converted into a PyTorch tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqHrZpNeGKzh"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "weights = weights.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#custom trainer is created in order to pass these calculated weights to a loss function called cross-entropy loss\n",
        "#cross entropy is useful for classificiation tasks as it compares the predicted probabilities to the actual class labels, there are obviously\n",
        "#various other loss functions is machine learning, but this one tends to perform well, making it a popular choice in ml\n",
        "\n",
        "#it is really good at penalising the model when it is confident about the wrong answer. it guides the model to pay attention\n",
        "#to the minority class and learn from its mistakes effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPK5icyuENTZ"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "#Custom trainer that extends the HuggingFace Trainer\n",
        "#cross entropy loss to handle imbalance data\n",
        "class CustomTrainer(HfTrainer):\n",
        "\n",
        "   def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs) #calls the contructor of the superclass (HfTrainer) amd sets up an instance variable self.weights.\n",
        "        self.weights = weights.to(model.device)\n",
        "\n",
        "   def compute_loss(self, model, inputs, return_outputs=False): # method that overrides the loss computation in the HfTrainer class\n",
        "        labels = inputs.pop(\"labels\") #extracts the labels from the input data\n",
        "        outputs = model(**inputs) # passes the remaining inputs to the model and gets the outputs, '**inputs' unpacks the dictionary into keyword arguments\n",
        "        logits = outputs.logits #extracts the logits from the model outputs\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=weights) # initialises the cross-entropy loss function with the class weights\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1)) #the loss between the logits and labels reshapes the logits if necessary.\n",
        "        return (loss, outputs) if return_outputs else loss # if true, returns a tuple of the loss and the outputs, else just returns the loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi34N51et5L3"
      },
      "source": [
        "# TESTING TRAINER FOR BEST PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#too low epochs - underfitting\n",
        "#too high epochs - overfitting\n",
        "\n",
        "#lower batch size - enhances generalisation and regularisation, but has long training time\n",
        "#higher batch size - poorer generalisation if too large, but speeds up training time. \n",
        "\n",
        "# important to find the \"sweet spot\", a good balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_FuoQ6wa7r4"
      },
      "outputs": [],
      "source": [
        "#random search to find the best parameters for the model\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "output_dir = \"output/{}\".format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define a grid of hyperparameters to search over\n",
        "param_grid = {\n",
        "    'learning_rate': [1e-5, 2e-5, 5e-5],\n",
        "    'num_train_epochs': [2, 3, 4, 5, 10],\n",
        "    'per_device_train_batch_size': [8, 16, 32]\n",
        "}\n",
        "\n",
        "# Create a sampler to randomly sample from the grid\n",
        "param_sampler = ParameterSampler(param_grid, n_iter=10, random_state=0)\n",
        "\n",
        "best_loss = np.inf\n",
        "best_params = {}\n",
        "\n",
        "for params in param_sampler:\n",
        "    print(f\"Training with parameters: {params}\")\n",
        "    args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        learning_rate=params['learning_rate'],\n",
        "        num_train_epochs=params['num_train_epochs'],\n",
        "        per_device_train_batch_size=params['per_device_train_batch_size'],\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",  # Save at the end of each epoch\n",
        "        logging_dir=f'{output_dir}/logs',  # Where to store logs\n",
        "        logging_steps=10,  # Log every 10 steps\n",
        "        load_best_model_at_end=True\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model\n",
        "    eval_results = trainer.evaluate()\n",
        "    if eval_results['eval_loss'] < best_loss:\n",
        "        best_loss = eval_results['eval_loss']\n",
        "        best_params = params\n",
        "        # Save the best model\n",
        "        model.save_pretrained(f\"{output_dir}/best_model\")\n",
        "\n",
        "print(f\"Best parameters: {best_params} with loss: {best_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kggPWeCZCl7i"
      },
      "outputs": [],
      "source": [
        "#choosing high parameters and letting the training stop with early stopping\n",
        "\n",
        "\n",
        "# TrainingArguments\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Clear the output directory or create a unique directory for the new run\n",
        "output_dir = \"output/{}\".format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=30,  # You can set this higher since early stopping will halt the training\n",
        "    per_device_train_batch_size=32,  # Adjust based on your dataset and GPU memory\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",  # Save at the end of each epoch\n",
        "    logging_dir=f'{output_dir}/logs',  # Where to store logs\n",
        "    logging_steps=10,  # Log every 10 steps\n",
        "    load_best_model_at_end=True,  # Whether to load the best model found at each evaluation.\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Stop if no improvement after 3 epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2i5poVfjSVC"
      },
      "source": [
        "# DEFINE PRIMARY TRAINER AND REQUIRED ARGUMENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "MQU24j_jIpeW",
        "outputId": "2a1cfeca-7932-41f8-a50d-af86e0d7be9a"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "# TrainingArguments\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Clear the output directory or create a unique directory for the next run\n",
        "output_dir = \"output/{}\".format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    # learning_rate=5e-05,\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",  # Save at the end of each epoch\n",
        "    logging_dir=f'{output_dir}/logs',  # Where to store logs\n",
        "    logging_steps=10,  # Log every 10 steps\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGyXp4L5oQ6i"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z80waxlkjX3V"
      },
      "source": [
        "# PLOT LEARNING CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CrCFbCA4jef"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "#function for plotting learning curve\n",
        "\n",
        "def plot_training_history(trainer):\n",
        "    # Retrieve the logged losses and accuracies from the trainer\n",
        "    training_losses = [entry['loss'] for entry in trainer.state.log_history if 'loss' in entry and 'epoch' in entry]\n",
        "    validation_losses = [entry['eval_loss'] for entry in trainer.state.log_history if 'eval_loss' in entry]\n",
        "    training_accuracies = [entry['eval_accuracy'] for entry in trainer.state.log_history if 'eval_accuracy' in entry]\n",
        "    # The lengths of training and validation metrics should match the number of epochs\n",
        "    min_length = min(len(training_losses), len(validation_losses), len(training_accuracies))\n",
        "    if min_length == 0:\n",
        "        raise ValueError(\"No training or validation metrics were recorded.\")\n",
        "\n",
        "    epochs = range(1, min_length + 1)\n",
        "    training_losses = training_losses[:min_length]\n",
        "    validation_losses = validation_losses[:min_length]\n",
        "    training_accuracies = training_accuracies[:min_length]\n",
        "\n",
        "    # Plotting Loss Graph\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, training_losses, label='Train Loss')\n",
        "    plt.plot(epochs, validation_losses, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotting Accuracy Graph\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, training_accuracies, label='Train Accuracy')\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbtInONlMMoh"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHoT8-V_nEud"
      },
      "outputs": [],
      "source": [
        "#to get the array values below to display in correct format\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDhfCVM6nEwn"
      },
      "outputs": [],
      "source": [
        "text = \"That was good point\"\n",
        "# text = \"Weekend pe shopping jaane ka plan hai, chalna hai?\"\n",
        "# text = \"go to hell\"\n",
        "# text = \"oh penchoda\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model(**inputs)\n",
        "print(outputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR-Bc-f3jcxx"
      },
      "source": [
        "# GET CONFUSION MATRIX AND CLASSIFICATION REPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA9huAOWd3y0"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Move model to the correct device (CPU or CUDA)\n",
        "model.to(device)\n",
        "\n",
        "# Prepare the validation dataset\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)\n",
        "\n",
        "# DataLoader for validation set\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "# Initialize lists to store true labels and predictions\n",
        "true_labels = []\n",
        "predictions = []\n",
        "\n",
        "# Iterate over validation data\n",
        "for batch in val_loader:\n",
        "    # Unpack batch and move to the correct device\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    # Forward pass, calculate logit predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    true_labels.extend(label_ids)\n",
        "    predictions.extend(np.argmax(logits, axis=1))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(true_labels, predictions)\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXpIP8o5jyYK"
      },
      "source": [
        "# SAVE MODEL AS STATE DICTIONARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qEfM6i06IfN"
      },
      "outputs": [],
      "source": [
        "#my addition to source code\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/model_state_dict.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QjBrn_Wbb_dg",
        "qQQzuYF4cGjj",
        "VgX1OGrYb5r0",
        "kZpPzgTDucTD",
        "tgdG4iI3vDzk",
        "oMUUVz0RxwZN",
        "nNkSeGtSFwhg",
        "iXKqjQ1Ei8Rr",
        "hDJfihgdjFOV",
        "sFSHUrHJjLIk",
        "Yi34N51et5L3",
        "k2i5poVfjSVC",
        "z80waxlkjX3V",
        "WR-Bc-f3jcxx",
        "IXpIP8o5jyYK"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
